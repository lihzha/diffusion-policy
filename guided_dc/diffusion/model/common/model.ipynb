{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from typing import Callable\n",
    "import timm\n",
    "\n",
    "# def get_resnet(name, weights=None, **kwargs):\n",
    "#     \"\"\"\n",
    "#     name: resnet18, resnet34, resnet50\n",
    "#     weights: \"IMAGENET1K_V1\", \"r3m\"\n",
    "#     \"\"\"\n",
    "#     # load r3m weights\n",
    "#     if (weights == \"r3m\") or (weights == \"R3M\"):\n",
    "#         return get_r3m(name=name, **kwargs)\n",
    "\n",
    "#     func = getattr(torchvision.models, name)\n",
    "#     resnet = func(weights=weights, **kwargs)\n",
    "#     resnet.fc = torch.nn.Identity()\n",
    "#     return resnet\n",
    "\n",
    "# def get_r3m(name, **kwargs):\n",
    "#     \"\"\"\n",
    "#     name: resnet18, resnet34, resnet50\n",
    "#     \"\"\"\n",
    "#     import r3m\n",
    "#     r3m.device = 'cpu'\n",
    "#     model = r3m.load_r3m(name)\n",
    "#     r3m_model = model.module\n",
    "#     resnet_model = r3m_model.convnet\n",
    "#     resnet_model = resnet_model.to('cpu')\n",
    "#     return resnet_model\n",
    "\n",
    "def replace_submodules(\n",
    "        root_module: nn.Module, \n",
    "        predicate: Callable[[nn.Module], bool], \n",
    "        func: Callable[[nn.Module], nn.Module]) -> nn.Module:\n",
    "    \"\"\"\n",
    "    predicate: Return true if the module is to be replaced.\n",
    "    func: Return new module to use.\n",
    "    \"\"\"\n",
    "    if predicate(root_module):\n",
    "        return func(root_module)\n",
    "\n",
    "    bn_list = [k.split('.') for k, m \n",
    "        in root_module.named_modules(remove_duplicate=True) \n",
    "        if predicate(m)]\n",
    "    for *parent, k in bn_list:\n",
    "        parent_module = root_module\n",
    "        if len(parent) > 0:\n",
    "            parent_module = root_module.get_submodule('.'.join(parent))\n",
    "        if isinstance(parent_module, nn.Sequential):\n",
    "            src_module = parent_module[int(k)]\n",
    "        else:\n",
    "            src_module = getattr(parent_module, k)\n",
    "        tgt_module = func(src_module)\n",
    "        if isinstance(parent_module, nn.Sequential):\n",
    "            parent_module[int(k)] = tgt_module\n",
    "        else:\n",
    "            setattr(parent_module, k, tgt_module)\n",
    "    # verify that all BN are replaced\n",
    "    bn_list = [k.split('.') for k, m \n",
    "        in root_module.named_modules(remove_duplicate=True) \n",
    "        if predicate(m)]\n",
    "    assert len(bn_list) == 0\n",
    "    return root_module\n",
    "   \n",
    "class ResNetEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name='resnet18',\n",
    "        # weights='IMAGENET1K_V1',\n",
    "        pretrained=False,\n",
    "        share_rgb_model=False,\n",
    "        num_views=3,\n",
    "        img_cond_steps=1,\n",
    "        use_group_norm=True,\n",
    "        frozen=False,\n",
    "        use_lora=False,\n",
    "        lora_rank=8\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_cond_steps = img_cond_steps\n",
    "        self.num_views = num_views\n",
    "        \n",
    "        assert 'resnet' in name\n",
    "        \n",
    "        if not share_rgb_model:\n",
    "            self.forward = self.forward_loop\n",
    "            self.model = nn.ModuleList()\n",
    "            for _ in range(num_views):\n",
    "                model = nn.Sequential(*list(timm.create_model(\n",
    "                    model_name=name,\n",
    "                    pretrained=pretrained,\n",
    "                    global_pool='',\n",
    "                    num_classes=0\n",
    "                ).children())[:-2]\n",
    "                )\n",
    "                model = nn.Sequential(model, nn.AdaptiveAvgPool2d(output_size=(1, 1)), nn.Flatten())\n",
    "                \n",
    "                self.model.append(model)\n",
    "    \n",
    "        else:\n",
    "            self.forward = self.forward_batch\n",
    "            self.model = timm.create_model(\n",
    "                model_name=name,\n",
    "                global_pool='',\n",
    "                pretrained=pretrained,\n",
    "                num_classes=0\n",
    "            )\n",
    "            \n",
    "            # Add a AdaptiveAvgPool2d(output_size=(1, 1)) layer to the model\n",
    "            self.model = nn.Sequential(\n",
    "                *list(self.model.children())[:-2],\n",
    "                nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "        if frozen:\n",
    "            assert pretrained\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        if use_lora:\n",
    "            import peft\n",
    "            assert pretrained and not frozen\n",
    "            lora_config = peft.LoraConfig(\n",
    "                r=lora_rank,\n",
    "                lora_alpha=8,\n",
    "                lora_dropout=0.0,\n",
    "                target_modules=[\"qkv\"],\n",
    "            )\n",
    "            model = peft.get_peft_model(model, lora_config)\n",
    "            model.print_trainable_parameters()\n",
    "            \n",
    "       \n",
    "        \n",
    "        if use_group_norm:\n",
    "            assert not pretrained\n",
    "            if isinstance(self.model, nn.ModuleList):\n",
    "                for i in range(num_views):\n",
    "                    self.model[i] = replace_submodules(\n",
    "                        root_module=self.model[i],\n",
    "                        predicate=lambda x: isinstance(x, nn.BatchNorm2d),\n",
    "                        func=lambda x: nn.GroupNorm(\n",
    "                            num_groups=x.num_features//16, \n",
    "                            num_channels=x.num_features)\n",
    "                    )\n",
    "            else:\n",
    "                self.model = replace_submodules(\n",
    "                    root_module=self.model,\n",
    "                    predicate=lambda x: isinstance(x, nn.BatchNorm2d),\n",
    "                    func=lambda x: nn.GroupNorm(\n",
    "                        num_groups=x.num_features//16, \n",
    "                        num_channels=x.num_features)\n",
    "                )\n",
    "            \n",
    "    @property\n",
    "    def repr_dim(self):\n",
    "        return 512 * self.img_cond_steps * self.num_views\n",
    "\n",
    "    def forward_loop(self, x: dict):\n",
    "        outputs = []\n",
    "        for v, f in zip(x.values(), self.model):\n",
    "            y = f(v)\n",
    "            y = einops.rearrange(y, \"(b cs) d -> b (cs d)\", cs=self.img_cond_steps)\n",
    "            outputs.append(y)\n",
    "        return torch.cat(outputs, dim=-1)  # bs, img_cond_steps*embed_dim*num_views\n",
    "    \n",
    "    def forward_batch(self, x: dict):\n",
    "        # x is a dict with keys as view names and values as images. Concatenate the images along the batch dimension and reshape to (batch, patch_nums, embed_dim) after passing through the embedding layer.\n",
    "\n",
    "       \n",
    "        x = torch.cat(list(x.values()), dim=0)\n",
    "        \n",
    "        y = self.model(x)\n",
    "        y = einops.rearrange(y, \"(bcs v) d -> bcs (v d)\", v=self.num_views)\n",
    "        y = einops.rearrange(y, \"(b cs) vd -> b (cs vd)\", cs=self.img_cond_steps)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ResNetEncoder(pretrained=False, num_views=2, img_cond_steps=2, share_rgb_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (9): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(a.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.forward({'a': torch.randn(2, 3, 240, 320), 'b': torch.randn(2, 3, 240, 320)}).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.repr_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def get_resnet(name, weights=None, **kwargs):\n",
    "    \"\"\"\n",
    "    name: resnet18, resnet34, resnet50\n",
    "    weights: \"IMAGENET1K_V1\", \"r3m\"\n",
    "    \"\"\"\n",
    "    # load r3m weights\n",
    "    if (weights == \"r3m\") or (weights == \"R3M\"):\n",
    "        return get_r3m(name=name, **kwargs)\n",
    "\n",
    "    func = getattr(torchvision.models, name)\n",
    "    resnet = func(weights=weights, **kwargs)\n",
    "    resnet.fc = torch.nn.Identity()\n",
    "    return resnet\n",
    "\n",
    "def get_r3m(name, **kwargs):\n",
    "    \"\"\"\n",
    "    name: resnet18, resnet34, resnet50\n",
    "    \"\"\"\n",
    "    import r3m\n",
    "    r3m.device = 'cpu'\n",
    "    model = r3m.load_r3m(name)\n",
    "    r3m_model = model.module\n",
    "    resnet_model = r3m_model.convnet\n",
    "    resnet_model = resnet_model.to('cpu')\n",
    "    return resnet_model\n",
    "\n",
    "b = get_resnet('resnet18', weights='IMAGENET1K_V1')\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from typing import Callable\n",
    "import timm\n",
    "   \n",
    "def replace_submodules(\n",
    "        root_module: nn.Module, \n",
    "        predicate: Callable[[nn.Module], bool], \n",
    "        func: Callable[[nn.Module], nn.Module]) -> nn.Module:\n",
    "    \"\"\"\n",
    "    predicate: Return true if the module is to be replaced.\n",
    "    func: Return new module to use.\n",
    "    \"\"\"\n",
    "    if predicate(root_module):\n",
    "        return func(root_module)\n",
    "\n",
    "    bn_list = [k.split('.') for k, m \n",
    "        in root_module.named_modules(remove_duplicate=True) \n",
    "        if predicate(m)]\n",
    "    for *parent, k in bn_list:\n",
    "        parent_module = root_module\n",
    "        if len(parent) > 0:\n",
    "            parent_module = root_module.get_submodule('.'.join(parent))\n",
    "        if isinstance(parent_module, nn.Sequential):\n",
    "            src_module = parent_module[int(k)]\n",
    "        else:\n",
    "            src_module = getattr(parent_module, k)\n",
    "        tgt_module = func(src_module)\n",
    "        if isinstance(parent_module, nn.Sequential):\n",
    "            parent_module[int(k)] = tgt_module\n",
    "        else:\n",
    "            setattr(parent_module, k, tgt_module)\n",
    "    # verify that all BN are replaced\n",
    "    bn_list = [k.split('.') for k, m \n",
    "        in root_module.named_modules(remove_duplicate=True) \n",
    "        if predicate(m)]\n",
    "    assert len(bn_list) == 0\n",
    "    return root_module\n",
    "   \n",
    "class TimmEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name='vit_base_patch14_dinov2.lvd142m',  # 'resnet18\n",
    "        # weights='IMAGENET1K_V1',\n",
    "        pretrained=False,\n",
    "        share_rgb_model=False,\n",
    "        num_views=3,\n",
    "        img_cond_steps=1,\n",
    "        frozen=False,\n",
    "        use_lora=False,\n",
    "        drop_path_rate=0.0,\n",
    "        lora_rank=8,\n",
    "        use_group_norm=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_cond_steps = img_cond_steps\n",
    "        self.num_views = num_views\n",
    "        self.model_name = name\n",
    "        \n",
    "        if 'vit' in name:\n",
    "            if not share_rgb_model:\n",
    "                self.forward = self.forward_loop\n",
    "                \n",
    "                self.model = nn.ModuleList([timm.create_model(\n",
    "                    model_name=name,\n",
    "                    pretrained=pretrained,\n",
    "                    global_pool='',    # '' means no pooling\n",
    "                    num_classes=0,              # remove classification layer\n",
    "                    img_size=224,    # 224\n",
    "                    drop_path_rate=drop_path_rate,  # stochastic depth\n",
    "                ) for _ in range(num_views)]\n",
    "                )\n",
    "        \n",
    "            else:\n",
    "                self.forward = self.forward_batch\n",
    "                self.model = timm.create_model(\n",
    "                    model_name=name,\n",
    "                    pretrained=pretrained,\n",
    "                    global_pool='',    # '' means no pooling\n",
    "                    num_classes=0,              # remove classification layer\n",
    "                    img_size=224,    # 224\n",
    "                    drop_path_rate=drop_path_rate,  # stochastic depth\n",
    "                )\n",
    "        \n",
    "        elif 'resnet' in name:\n",
    "            if not share_rgb_model:\n",
    "                self.forward = self.forward_loop\n",
    "                self.model = nn.ModuleList()\n",
    "                for _ in range(num_views):\n",
    "                    model = nn.Sequential(*list(timm.create_model(\n",
    "                        model_name=name,\n",
    "                        pretrained=pretrained,\n",
    "                        global_pool='',\n",
    "                        num_classes=0\n",
    "                    ).children())[:-2]\n",
    "                    )\n",
    "                    model = nn.Sequential(model, nn.AdaptiveAvgPool2d(output_size=(1, 1)), nn.Flatten())\n",
    "                    \n",
    "                    self.model.append(model)\n",
    "        \n",
    "            else:\n",
    "                self.forward = self.forward_batch\n",
    "                self.model = timm.create_model(\n",
    "                    model_name=name,\n",
    "                    global_pool='',\n",
    "                    pretrained=pretrained,\n",
    "                    num_classes=0\n",
    "                )   \n",
    "                # Add a AdaptiveAvgPool2d(output_size=(1, 1)) layer to the model\n",
    "                self.model = nn.Sequential(\n",
    "                    *list(self.model.children())[:-2],\n",
    "                    nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "                    nn.Flatten()\n",
    "                )\n",
    "        \n",
    "        if frozen:\n",
    "            assert pretrained\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        if use_lora:\n",
    "            import peft\n",
    "            assert pretrained and not frozen\n",
    "            lora_config = peft.LoraConfig(\n",
    "                r=lora_rank,\n",
    "                lora_alpha=8,\n",
    "                lora_dropout=0.0,\n",
    "                target_modules=[\"qkv\"],\n",
    "            )\n",
    "            model = peft.get_peft_model(model, lora_config)\n",
    "            model.print_trainable_parameters()\n",
    "        \n",
    "        if use_group_norm:\n",
    "            assert not pretrained and 'resnet' in name\n",
    "            if isinstance(self.model, nn.ModuleList):\n",
    "                for i in range(num_views):\n",
    "                    self.model[i] = replace_submodules(\n",
    "                        root_module=self.model[i],\n",
    "                        predicate=lambda x: isinstance(x, nn.BatchNorm2d),\n",
    "                        func=lambda x: nn.GroupNorm(\n",
    "                            num_groups=x.num_features//16, \n",
    "                            num_channels=x.num_features)\n",
    "                    )\n",
    "            else:\n",
    "                self.model = replace_submodules(\n",
    "                    root_module=self.model,\n",
    "                    predicate=lambda x: isinstance(x, nn.BatchNorm2d),\n",
    "                    func=lambda x: nn.GroupNorm(\n",
    "                        num_groups=x.num_features//16, \n",
    "                        num_channels=x.num_features)\n",
    "                )\n",
    "        \n",
    "       \n",
    "    @property\n",
    "    def repr_dim(self):\n",
    "        if 'resnet' in self.model_name:\n",
    "            return 512 * self.img_cond_steps * self.num_views\n",
    "\n",
    "    def forward_loop(self, x: dict):\n",
    "        outputs = []\n",
    "        for v, f in zip(x.values(), self.model):\n",
    "            y = f(v)\n",
    "            y = einops.rearrange(y, \"(b cs) d -> b (cs d)\", cs=self.img_cond_steps)\n",
    "            outputs.append(y)\n",
    "        return torch.cat(outputs, dim=-1)  # bs, img_cond_steps*embed_dim*num_views\n",
    "    \n",
    "    def forward_batch(self, x: dict):\n",
    "        # x is a dict with keys as view names and values as images. Concatenate the images along the batch dimension and reshape to (batch, patch_nums, embed_dim) after passing through the embedding layer.\n",
    "\n",
    "       \n",
    "        x = torch.cat(list(x.values()), dim=0)\n",
    "        \n",
    "        y = self.model(x)\n",
    "        y = einops.rearrange(y, \"(bcs v) d -> bcs (v d)\", v=self.num_views)\n",
    "        y = einops.rearrange(y, \"(b cs) vd -> b (cs vd)\", cs=self.img_cond_steps)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimmEncoder(pretrained=False, num_views=2, img_cond_steps=2, share_rgb_model=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "droid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
